{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd818d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42da927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else\n",
    "                      \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3a5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle_Boot')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.FashionMNIST(\n",
    "    \"data\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    \"data\",\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2112fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*4*4, 400)\n",
    "        self.fc2 = nn.Linear(400, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "all_criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer1 = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "optimizer2 = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc317436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7bb530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ec428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 163.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.4670 val_loss=0.3383 train_acc=0.833 val_acc=0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 180.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.2906 val_loss=0.2916 train_acc=0.892 val_acc=0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 176.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.2468 val_loss=0.2609 train_acc=0.909 val_acc=0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 175.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.2196 val_loss=0.2822 train_acc=0.917 val_acc=0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 175.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.1963 val_loss=0.2792 train_acc=0.928 val_acc=0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 179.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.1784 val_loss=0.2460 train_acc=0.934 val_acc=0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 177.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.1603 val_loss=0.2742 train_acc=0.939 val_acc=0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 177.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.1450 val_loss=0.2542 train_acc=0.947 val_acc=0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 177.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.1299 val_loss=0.2632 train_acc=0.951 val_acc=0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 177.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.1166 val_loss=0.2717 train_acc=0.957 val_acc=0.914\n"
     ]
    }
   ],
   "source": [
    "writer_sgd = SummaryWriter(\"runs/sgd_fashion\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    running_loss, correct, seen = 0.0, 0, 0\n",
    "    for imgs, labels in tqdm(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer1.zero_grad(set_to_none=True)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        correct += (logits.argmax(1) == labels).sum().item()\n",
    "        seen += imgs.size(0)\n",
    "\n",
    "    train_loss = running_loss / seen\n",
    "    train_acc = correct / seen\n",
    "    writer_sgd.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer_sgd.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    v_running, v_correct, v_seen = 0.0, 0, 0\n",
    "    all_labels_list, all_predictions_list, all_losses_list = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            v_running += loss.item() * imgs.size(0)\n",
    "            v_correct += (logits.argmax(1) == labels).sum().item()\n",
    "            v_seen += imgs.size(0)\n",
    "\n",
    "            all_losses_list.append(all_criterion(logits, labels).cpu())\n",
    "            all_predictions_list.append(logits.argmax(1).cpu())\n",
    "            all_labels_list.append(labels.cpu())\n",
    "\n",
    "    val_loss = v_running / v_seen\n",
    "    val_acc = v_correct / v_seen\n",
    "    writer_sgd.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer_sgd.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n",
    "          f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f}\")\n",
    "\n",
    "writer_sgd.flush()\n",
    "writer_sgd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05531d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 145.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.1912 val_loss=0.3298 train_acc=0.929 val_acc=0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 154.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.1616 val_loss=0.2978 train_acc=0.940 val_acc=0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 156.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.1401 val_loss=0.2730 train_acc=0.947 val_acc=0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 156.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.1245 val_loss=0.2675 train_acc=0.953 val_acc=0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 155.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.1086 val_loss=0.2937 train_acc=0.959 val_acc=0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 152.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.1002 val_loss=0.3060 train_acc=0.963 val_acc=0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 157.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.0897 val_loss=0.3326 train_acc=0.966 val_acc=0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 156.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.0797 val_loss=0.3130 train_acc=0.970 val_acc=0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 156.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.0702 val_loss=0.3388 train_acc=0.974 val_acc=0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:05<00:00, 156.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.0630 val_loss=0.3874 train_acc=0.977 val_acc=0.909\n"
     ]
    }
   ],
   "source": [
    "writer_adam = SummaryWriter(\"runs/adam_fashion\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    running_loss, correct, seen = 0.0, 0, 0\n",
    "    for imgs, labels in tqdm(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer2.zero_grad(set_to_none=True)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        correct += (logits.argmax(1) == labels).sum().item()\n",
    "        seen += imgs.size(0)\n",
    "\n",
    "    train_loss = running_loss / seen\n",
    "    train_acc = correct / seen\n",
    "    writer_adam.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer_adam.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    v_running, v_correct, v_seen = 0.0, 0, 0\n",
    "    all_labels_list, all_predictions_list, all_losses_list = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            v_running += loss.item() * imgs.size(0)\n",
    "            v_correct += (logits.argmax(1) == labels).sum().item()\n",
    "            v_seen += imgs.size(0)\n",
    "\n",
    "            all_losses_list.append(all_criterion(logits, labels).cpu())\n",
    "            all_predictions_list.append(logits.argmax(1).cpu())\n",
    "            all_labels_list.append(labels.cpu())\n",
    "\n",
    "    val_loss = v_running / v_seen\n",
    "    val_acc = v_correct / v_seen\n",
    "    writer_adam.add_scalar('Loss/val', val_loss, epoch)\n",
    "    writer_adam.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n",
    "          f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f}\")\n",
    "\n",
    "writer_adam.flush()\n",
    "writer_adam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5777b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
