{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761783c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\"../\", train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(\"../\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b743a2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CIFAR10 in module torchvision.datasets.cifar:\n",
      "\n",
      "class CIFAR10(torchvision.datasets.vision.VisionDataset)\n",
      " |  CIFAR10(root: Union[str, pathlib.Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      " |\n",
      " |  `CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
      " |\n",
      " |  Args:\n",
      " |      root (str or ``pathlib.Path``): Root directory of dataset where directory\n",
      " |          ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
      " |      train (bool, optional): If True, creates dataset from training set, otherwise\n",
      " |          creates from test set.\n",
      " |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      " |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      " |      target_transform (callable, optional): A function/transform that takes in the\n",
      " |          target and transforms it.\n",
      " |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      " |          puts it in root directory. If dataset is already downloaded, it is not\n",
      " |          downloaded again.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      CIFAR10\n",
      " |      torchvision.datasets.vision.VisionDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      " |      Args:\n",
      " |          index (int): Index\n",
      " |\n",
      " |      Returns:\n",
      " |          tuple: (image, target) where target is index of the target class.\n",
      " |\n",
      " |  __init__(self, root: Union[str, pathlib.Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __len__(self) -> int\n",
      " |\n",
      " |  download(self) -> None\n",
      " |\n",
      " |  extra_repr(self) -> str\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  base_folder = 'cifar-10-batches-py'\n",
      " |\n",
      " |  filename = 'cifar-10-python.tar.gz'\n",
      " |\n",
      " |  meta = {'filename': 'batches.meta', 'key': 'label_names', 'md5': '5ff9...\n",
      " |\n",
      " |  test_list = [['test_batch', '40351d587109b95175f43aff81a1287e']]\n",
      " |\n",
      " |  tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
      " |\n",
      " |  train_list = [['data_batch_1', 'c99cafc152244af753f735de768cd75f'], ['...\n",
      " |\n",
      " |  url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      " |\n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |\n",
      " |  __add__(self, other: 'Dataset[_T_co]') -> 'ConcatDataset[_T_co]'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |\n",
      " |  __orig_bases__ = (typing.Generic[+_T_co],)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datasets.CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.cifar.CIFAR10,\n",
       " torchvision.datasets.vision.VisionDataset,\n",
       " torch.utils.data.dataset.Dataset,\n",
       " typing.Generic,\n",
       " object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar10).__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f136f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa83893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516a13a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 1, 'automobile')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar10[99]\n",
    "img, label, class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c328177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a52a07c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AugMix',\n",
       " 'AutoAugment',\n",
       " 'AutoAugmentPolicy',\n",
       " 'CenterCrop',\n",
       " 'ColorJitter',\n",
       " 'Compose',\n",
       " 'ConvertImageDtype',\n",
       " 'ElasticTransform',\n",
       " 'FiveCrop',\n",
       " 'GaussianBlur',\n",
       " 'Grayscale',\n",
       " 'InterpolationMode',\n",
       " 'Lambda',\n",
       " 'LinearTransformation',\n",
       " 'Normalize',\n",
       " 'PILToTensor',\n",
       " 'Pad',\n",
       " 'RandAugment',\n",
       " 'RandomAdjustSharpness',\n",
       " 'RandomAffine',\n",
       " 'RandomApply',\n",
       " 'RandomAutocontrast',\n",
       " 'RandomChoice',\n",
       " 'RandomCrop',\n",
       " 'RandomEqualize',\n",
       " 'RandomErasing',\n",
       " 'RandomGrayscale',\n",
       " 'RandomHorizontalFlip',\n",
       " 'RandomInvert',\n",
       " 'RandomOrder',\n",
       " 'RandomPerspective',\n",
       " 'RandomPosterize',\n",
       " 'RandomResizedCrop',\n",
       " 'RandomRotation',\n",
       " 'RandomSolarize',\n",
       " 'RandomVerticalFlip',\n",
       " 'Resize',\n",
       " 'TenCrop',\n",
       " 'ToPILImage',\n",
       " 'ToTensor',\n",
       " 'TrivialAugmentWide',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functional_pil',\n",
       " '_functional_tensor',\n",
       " '_presets',\n",
       " 'autoaugment',\n",
       " 'functional',\n",
       " 'transforms']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d28f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10(\"../\", train=True, download=False,\n",
    "                                  transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300a8173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.Size([3, 32, 32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t, _ = tensor_cifar10[99]\n",
    "img_t.dtype, img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeadbf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.min(), img_t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ddf85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12c7810d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_t.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910e36ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.arange(0, 12).reshape(4, 3)\n",
    "\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f537644",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8053a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b24b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b489bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab6f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(\"../\", train=True, download=False,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=(0.4915, 0.4823, 0.4468),\n",
    "                                                                std=(0.2470, 0.2435, 0.2616))\n",
    "                                       ]))\n",
    "transformed_cifar10_val = datasets.CIFAR10(\"../\", train=False, download=False,\n",
    "                                           transform=transforms.Compose([\n",
    "                                            transforms.ToTensor()                                               \n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea9c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.9806982..2.126078].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12c6fba70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_t, _ = transformed_cifar10[99]\n",
    "plt.imshow(img_t.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e46f8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = [\"airplane\", \"bird\"]\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in transformed_cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in transformed_cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73ef823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        (\"fc1\", nn.Linear(in_features=3072, out_features=512)),\n",
    "        (\"tanh\", nn.Tanh()),\n",
    "        (\"fc2\", nn.Linear(512, n_out))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d6e1503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.8628641..2.029448].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "208b9ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5afc522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e55262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3391, -0.0934]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f50618ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e119047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    ")\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb719822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7520, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a83a03ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53fcb40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss 6.492502689361572\n",
      "Epoch: 1, Loss 2.2003977298736572\n",
      "Epoch: 2, Loss 1.9473179578781128\n",
      "Epoch: 3, Loss 2.4837019443511963\n",
      "Epoch: 4, Loss 5.643917560577393\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "lr = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = criterion(out, torch.tensor([label]))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch: {epoch}, Loss {float(loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1146f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af851b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss 0.32965677976608276\n",
      "Epoch: 1, Loss 0.3370841145515442\n",
      "Epoch: 2, Loss 0.4352153539657593\n",
      "Epoch: 3, Loss 0.24158453941345215\n",
      "Epoch: 4, Loss 0.35769280791282654\n",
      "Epoch: 5, Loss 0.45000845193862915\n",
      "Epoch: 6, Loss 0.4502984285354614\n",
      "Epoch: 7, Loss 0.38442033529281616\n",
      "Epoch: 8, Loss 0.25918692350387573\n",
      "Epoch: 9, Loss 0.2384536862373352\n",
      "Epoch: 10, Loss 0.24110369384288788\n",
      "Epoch: 11, Loss 0.3369191884994507\n",
      "Epoch: 12, Loss 0.3728094696998596\n",
      "Epoch: 13, Loss 0.4137114882469177\n",
      "Epoch: 14, Loss 0.25002264976501465\n",
      "Epoch: 15, Loss 0.22865761816501617\n",
      "Epoch: 16, Loss 0.3887284994125366\n",
      "Epoch: 17, Loss 0.4494500458240509\n",
      "Epoch: 18, Loss 0.1784142553806305\n",
      "Epoch: 19, Loss 0.22830449044704437\n",
      "Epoch: 20, Loss 0.23501186072826385\n",
      "Epoch: 21, Loss 0.20343433320522308\n",
      "Epoch: 22, Loss 0.35672247409820557\n",
      "Epoch: 23, Loss 0.12574294209480286\n",
      "Epoch: 24, Loss 0.22919175028800964\n",
      "Epoch: 25, Loss 0.40607866644859314\n",
      "Epoch: 26, Loss 0.1250978410243988\n",
      "Epoch: 27, Loss 0.2575172781944275\n",
      "Epoch: 28, Loss 0.10675191134214401\n",
      "Epoch: 29, Loss 0.18327656388282776\n",
      "Epoch: 30, Loss 0.19330233335494995\n",
      "Epoch: 31, Loss 0.34373995661735535\n",
      "Epoch: 32, Loss 0.3455548882484436\n",
      "Epoch: 33, Loss 0.1638277769088745\n",
      "Epoch: 34, Loss 0.18295076489448547\n",
      "Epoch: 35, Loss 0.1964849829673767\n",
      "Epoch: 36, Loss 0.13109856843948364\n",
      "Epoch: 37, Loss 0.07353273034095764\n",
      "Epoch: 38, Loss 0.41665393114089966\n",
      "Epoch: 39, Loss 0.06545928865671158\n",
      "Epoch: 40, Loss 0.03296710550785065\n",
      "Epoch: 41, Loss 0.08268656581640244\n",
      "Epoch: 42, Loss 0.06820595264434814\n",
      "Epoch: 43, Loss 0.10416442155838013\n",
      "Epoch: 44, Loss 0.28730839490890503\n",
      "Epoch: 45, Loss 0.030975783243775368\n",
      "Epoch: 46, Loss 0.07776017487049103\n",
      "Epoch: 47, Loss 0.16040368378162384\n",
      "Epoch: 48, Loss 0.14911440014839172\n",
      "Epoch: 49, Loss 0.02939688414335251\n",
      "Epoch: 50, Loss 0.09548221528530121\n",
      "Epoch: 51, Loss 0.06129501760005951\n",
      "Epoch: 52, Loss 0.12471964955329895\n",
      "Epoch: 53, Loss 0.06543120741844177\n",
      "Epoch: 54, Loss 0.07330156862735748\n",
      "Epoch: 55, Loss 0.16753914952278137\n",
      "Epoch: 56, Loss 0.023106170818209648\n",
      "Epoch: 57, Loss 0.0622236505150795\n",
      "Epoch: 58, Loss 0.05520561710000038\n",
      "Epoch: 59, Loss 0.07733914256095886\n",
      "Epoch: 60, Loss 0.1694115847349167\n",
      "Epoch: 61, Loss 0.020925099030137062\n",
      "Epoch: 62, Loss 0.07666590809822083\n",
      "Epoch: 63, Loss 0.02592131868004799\n",
      "Epoch: 64, Loss 0.0712745413184166\n",
      "Epoch: 65, Loss 0.02964707650244236\n",
      "Epoch: 66, Loss 0.26989251375198364\n",
      "Epoch: 67, Loss 0.03824703022837639\n",
      "Epoch: 68, Loss 0.02485717460513115\n",
      "Epoch: 69, Loss 0.0367293581366539\n",
      "Epoch: 70, Loss 0.08890184760093689\n",
      "Epoch: 71, Loss 0.010739415884017944\n",
      "Epoch: 72, Loss 0.041349947452545166\n",
      "Epoch: 73, Loss 0.0374034121632576\n",
      "Epoch: 74, Loss 0.024090219289064407\n",
      "Epoch: 75, Loss 0.017978547140955925\n",
      "Epoch: 76, Loss 0.02231854945421219\n",
      "Epoch: 77, Loss 0.01744956523180008\n",
      "Epoch: 78, Loss 0.03500703349709511\n",
      "Epoch: 79, Loss 0.08416353166103363\n",
      "Epoch: 80, Loss 0.0458148717880249\n",
      "Epoch: 81, Loss 0.008344968780875206\n",
      "Epoch: 82, Loss 0.011055764742195606\n",
      "Epoch: 83, Loss 0.013757152482867241\n",
      "Epoch: 84, Loss 0.029353756457567215\n",
      "Epoch: 85, Loss 0.049527931958436966\n",
      "Epoch: 86, Loss 0.05027426406741142\n",
      "Epoch: 87, Loss 0.03198665380477905\n",
      "Epoch: 88, Loss 0.02234509401023388\n",
      "Epoch: 89, Loss 0.017603861168026924\n",
      "Epoch: 90, Loss 0.011176178231835365\n",
      "Epoch: 91, Loss 0.017802264541387558\n",
      "Epoch: 92, Loss 0.014063258655369282\n",
      "Epoch: 93, Loss 0.009110044687986374\n",
      "Epoch: 94, Loss 0.010336775332689285\n",
      "Epoch: 95, Loss 0.008466769009828568\n",
      "Epoch: 96, Loss 0.014095449820160866\n",
      "Epoch: 97, Loss 0.009110966697335243\n",
      "Epoch: 98, Loss 0.04761698469519615\n",
      "Epoch: 99, Loss 0.07084629684686661\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2)\n",
    ").to(device)\n",
    "\n",
    "lr = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1).to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch: {epoch}, Loss {float(loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea76e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "64\n",
      "64 \n",
      "\n",
      "\n",
      "16\n",
      "16 \n",
      "\n",
      "\n",
      "Accuracy: 0.552\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(cifar2_val, batch_size=64, shuffle=False, num_workers=10)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        batch_size = imgs.shape[0]\n",
    "        print(batch_size)\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        print(labels.shape[0], \"\\n\\n\")\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy: {correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53ad6577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574402, [1572864, 512, 1024, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in model.parameters() if p.requires_grad == True]\n",
    "\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a8085c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(4, 4), stride=(1, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "conv = nn.Conv2d(3, 16, kernel_size=4)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcf6171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 4, 4]), torch.Size([16]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape, conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2da0ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2d in module torch.nn.modules.conv:\n",
      "\n",
      "class Conv2d(_ConvNd)\n",
      " |  Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, tuple[int, int]], stride: Union[int, tuple[int, int]] = 1, padding: Union[str, int, tuple[int, int]] = 0, dilation: Union[int, tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None\n",
      " |\n",
      " |  Applies a 2D convolution over an input signal composed of several input\n",
      " |  planes.\n",
      " |\n",
      " |  In the simplest case, the output value of the layer with input size\n",
      " |  :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
      " |  can be precisely described as:\n",
      " |\n",
      " |  .. math::\n",
      " |      \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
      " |      \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
      " |\n",
      " |\n",
      " |  where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
      " |  :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
      " |  :math:`H` is a height of input planes in pixels, and :math:`W` is\n",
      " |  width in pixels.\n",
      " |\n",
      " |\n",
      " |  This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      " |\n",
      " |  On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      " |\n",
      " |  * :attr:`stride` controls the stride for the cross-correlation, a single\n",
      " |    number or a tuple.\n",
      " |\n",
      " |  * :attr:`padding` controls the amount of padding applied to the input. It\n",
      " |    can be either a string {'valid', 'same'} or an int / a tuple of ints giving the\n",
      " |    amount of implicit padding applied on both sides.\n",
      " |\n",
      " |  * :attr:`dilation` controls the spacing between the kernel points; also\n",
      " |    known as the  trous algorithm. It is harder to describe, but this `link`_\n",
      " |    has a nice visualization of what :attr:`dilation` does.\n",
      " |\n",
      " |\n",
      " |  * :attr:`groups` controls the connections between inputs and outputs.\n",
      " |    :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
      " |    :attr:`groups`. For example,\n",
      " |\n",
      " |      * At groups=1, all inputs are convolved to all outputs.\n",
      " |      * At groups=2, the operation becomes equivalent to having two conv\n",
      " |        layers side by side, each seeing half the input channels\n",
      " |        and producing half the output channels, and both subsequently\n",
      " |        concatenated.\n",
      " |      * At groups= :attr:`in_channels`, each input channel is convolved with\n",
      " |        its own set of filters (of size\n",
      " |        :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
      " |\n",
      " |  The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
      " |\n",
      " |      - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
      " |      - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
      " |        and the second `int` for the width dimension\n",
      " |\n",
      " |  Note:\n",
      " |      When `groups == in_channels` and `out_channels == K * in_channels`,\n",
      " |      where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
      " |\n",
      " |      In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
      " |      a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
      " |      :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
      " |\n",
      " |  Note:\n",
      " |      In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      " |\n",
      " |  Note:\n",
      " |      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
      " |      the input so the output has the shape as the input. However, this mode\n",
      " |      doesn't support any stride values other than 1.\n",
      " |\n",
      " |  Note:\n",
      " |      This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
      " |\n",
      " |  Args:\n",
      " |      in_channels (int): Number of channels in the input image\n",
      " |      out_channels (int): Number of channels produced by the convolution\n",
      " |      kernel_size (int or tuple): Size of the convolving kernel\n",
      " |      stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      " |      padding (int, tuple or str, optional): Padding added to all four sides of\n",
      " |          the input. Default: 0\n",
      " |      dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
      " |      groups (int, optional): Number of blocked connections from input\n",
      " |          channels to output channels. Default: 1\n",
      " |      bias (bool, optional): If ``True``, adds a learnable bias to the\n",
      " |          output. Default: ``True``\n",
      " |      padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
      " |          ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
      " |\n",
      " |\n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
      " |      - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
      " |\n",
      " |        .. math::\n",
      " |            H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
      " |                      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
      " |\n",
      " |        .. math::\n",
      " |            W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
      " |                      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
      " |\n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape\n",
      " |          :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
      " |          :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
      " |          The values of these weights are sampled from\n",
      " |          :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |          :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      " |      bias (Tensor):   the learnable bias of the module of shape\n",
      " |          (out_channels). If :attr:`bias` is ``True``,\n",
      " |          then the values of these weights are\n",
      " |          sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |          :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      " |\n",
      " |  Examples:\n",
      " |\n",
      " |      >>> # With square kernels and equal stride\n",
      " |      >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
      " |      >>> # non-square kernels and unequal stride and with padding\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
      " |      >>> # non-square kernels and unequal stride and with padding and dilation\n",
      " |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
      " |      >>> input = torch.randn(20, 16, 50, 100)\n",
      " |      >>> output = m(input)\n",
      " |\n",
      " |  .. _cross-correlation:\n",
      " |      https://en.wikipedia.org/wiki/Cross-correlation\n",
      " |\n",
      " |  .. _link:\n",
      " |      https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Conv2d\n",
      " |      _ConvNd\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, in_channels: int, out_channels: int, kernel_size: Union[int, tuple[int, int]], stride: Union[int, tuple[int, int]] = 1, padding: Union[str, int, tuple[int, int]] = 0, dilation: Union[int, tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None\n",
      " |      Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |\n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Define the computation performed at every call.\n",
      " |\n",
      " |      Should be overridden by all subclasses.\n",
      " |\n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _ConvNd:\n",
      " |\n",
      " |  __setstate__(self, state)\n",
      " |\n",
      " |  extra_repr(self)\n",
      " |      Return the extra representation of the module.\n",
      " |\n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |\n",
      " |  reset_parameters(self) -> None\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _ConvNd:\n",
      " |\n",
      " |  __constants__ = ['stride', 'padding', 'dilation', 'groups', 'padding_m...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |\n",
      " |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n",
      " |\n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |\n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |\n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |      # It is crucial that the return type is not annotated as `Any`, otherwise type checking\n",
      " |      # on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\n",
      " |      # https://github.com/pytorch/pytorch/pull/115074\n",
      " |\n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |\n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Add a child module to the current module.\n",
      " |\n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |\n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |\n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\n",
      " |\n",
      " |      Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |\n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |\n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  buffers(self, recurse: bool = True) -> collections.abc.Iterator[torch.Tensor]\n",
      " |      Return an iterator over module buffers.\n",
      " |\n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |\n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |\n",
      " |  children(self) -> collections.abc.Iterator['Module']\n",
      " |      Return an iterator over immediate children modules.\n",
      " |\n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |\n",
      " |  compile(self, *args, **kwargs)\n",
      " |      Compile this Module's forward using :func:`torch.compile`.\n",
      " |\n",
      " |      This Module's `__call__` method is compiled and all arguments are passed as-is\n",
      " |      to :func:`torch.compile`.\n",
      " |\n",
      " |      See :func:`torch.compile` for details on the arguments for this function.\n",
      " |\n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Move all model parameters and buffers to the CPU.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the GPU.\n",
      " |\n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing the optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Set the module in evaluation mode.\n",
      " |\n",
      " |      This has an effect only on certain modules. See the documentation of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, i.e. whether they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |\n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |\n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Return the buffer given by ``target`` if it exists, otherwise throw an error.\n",
      " |\n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |\n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |\n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |\n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |\n",
      " |  get_extra_state(self) -> Any\n",
      " |      Return any extra state to include in the module's state_dict.\n",
      " |\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |\n",
      " |      Note that extra state should be picklable to ensure working serialization\n",
      " |      of the state_dict. We only provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |\n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |\n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Return the parameter given by ``target`` if it exists, otherwise throw an error.\n",
      " |\n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |\n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |\n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |\n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |\n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Return the submodule given by ``target`` if it exists, otherwise throw an error.\n",
      " |\n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |\n",
      " |      .. code-block:: text\n",
      " |\n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |\n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` which has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |\n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |\n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |\n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |\n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |\n",
      " |      Raises:\n",
      " |          AttributeError: If at any point along the path resulting from\n",
      " |              the target string the (sub)path resolves to a non-existent\n",
      " |              attribute name or an object that is not an instance of ``nn.Module``.\n",
      " |\n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the IPU.\n",
      " |\n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing the optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  load_state_dict(self, state_dict: collections.abc.Mapping[str, typing.Any], strict: bool = True, assign: bool = False)\n",
      " |      Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\n",
      " |\n",
      " |      If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |\n",
      " |      .. warning::\n",
      " |          If :attr:`assign` is ``True`` the optimizer must be created after\n",
      " |          the call to :attr:`load_state_dict` unless\n",
      " |          :func:`~torch.__future__.get_swap_module_params_on_conversion` is ``True``.\n",
      " |\n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |          assign (bool, optional): When set to ``False``, the properties of the tensors\n",
      " |              in the current module are preserved whereas setting it to ``True`` preserves\n",
      " |              properties of the Tensors in the state dict. The only\n",
      " |              exception is the ``requires_grad`` field of :class:`~torch.nn.Parameter`s\n",
      " |              for which the value from the module is preserved.\n",
      " |              Default: ``False``\n",
      " |\n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing any keys that are expected\n",
      " |                  by this module but missing from the provided ``state_dict``.\n",
      " |              * **unexpected_keys** is a list of str containing the keys that are not\n",
      " |                  expected by this module but present in the provided ``state_dict``.\n",
      " |\n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |\n",
      " |  modules(self) -> collections.abc.Iterator['Module']\n",
      " |      Return an iterator over all modules in the network.\n",
      " |\n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |\n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |\n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |\n",
      " |  mtia(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the MTIA.\n",
      " |\n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing the optimizer if the module will\n",
      " |      live on MTIA while being optimized.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> collections.abc.Iterator[tuple[str, torch.Tensor]]\n",
      " |      Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.\n",
      " |\n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool, optional): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module. Defaults to True.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n",
      " |\n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>     if name in ['running_var']:\n",
      " |          >>>         print(buf.size())\n",
      " |\n",
      " |  named_children(self) -> collections.abc.Iterator[tuple[str, 'Module']]\n",
      " |      Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\n",
      " |\n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |\n",
      " |  named_modules(self, memo: Optional[set['Module']] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\n",
      " |\n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |\n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |\n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |\n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |\n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> collections.abc.Iterator[tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n",
      " |\n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated\n",
      " |              parameters in the result. Defaults to True.\n",
      " |\n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>     if name in ['bias']:\n",
      " |          >>>         print(param.size())\n",
      " |\n",
      " |  parameters(self, recurse: bool = True) -> collections.abc.Iterator[torch.nn.parameter.Parameter]\n",
      " |      Return an iterator over module parameters.\n",
      " |\n",
      " |      This is typically passed to an optimizer.\n",
      " |\n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |\n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |\n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[tuple[torch.Tensor, ...], torch.Tensor], Union[tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |\n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |\n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |\n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Add a buffer to the module.\n",
      " |\n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |\n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |\n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |\n",
      " |  register_forward_hook(self, hook: Union[Callable[[~T, tuple[Any, ...], Any], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward hook on the module.\n",
      " |\n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |\n",
      " |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      output. It can modify the input inplace but it will not have effect on\n",
      " |      forward since this is called after :func:`forward` is called. The hook\n",
      " |      should have the following signature::\n",
      " |\n",
      " |          hook(module, args, output) -> None or modified output\n",
      " |\n",
      " |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      " |      ``kwargs`` given to the forward function and be expected to return the\n",
      " |      output possibly modified. The hook should have the following signature::\n",
      " |\n",
      " |          hook(module, args, kwargs, output) -> None or modified output\n",
      " |\n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      " |              before all existing ``forward`` hooks on this\n",
      " |              :class:`torch.nn.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward`` hooks on\n",
      " |              this :class:`torch.nn.Module`. Note that global\n",
      " |              ``forward`` hooks registered with\n",
      " |              :func:`register_module_forward_hook` will fire before all hooks\n",
      " |              registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      " |              kwargs given to the forward function.\n",
      " |              Default: ``False``\n",
      " |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n",
      " |              whether an exception is raised while calling the Module.\n",
      " |              Default: ``False``\n",
      " |\n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |\n",
      " |  register_forward_pre_hook(self, hook: Union[Callable[[~T, tuple[Any, ...]], Optional[Any]], Callable[[~T, tuple[Any, ...], dict[str, Any]], Optional[tuple[Any, dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward pre-hook on the module.\n",
      " |\n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |\n",
      " |\n",
      " |      If ``with_kwargs`` is false or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      input. User can either return a tuple or a single modified value in the\n",
      " |      hook. We will wrap the value into a tuple if a single value is returned\n",
      " |      (unless that value is already a tuple). The hook should have the\n",
      " |      following signature::\n",
      " |\n",
      " |          hook(module, args) -> None or modified input\n",
      " |\n",
      " |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n",
      " |      kwargs given to the forward function. And if the hook modifies the\n",
      " |      input, both the args and kwargs should be returned. The hook should have\n",
      " |      the following signature::\n",
      " |\n",
      " |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n",
      " |\n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``forward_pre`` hooks on this\n",
      " |              :class:`torch.nn.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n",
      " |              on this :class:`torch.nn.Module`. Note that global\n",
      " |              ``forward_pre`` hooks registered with\n",
      " |              :func:`register_module_forward_pre_hook` will fire before all\n",
      " |              hooks registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n",
      " |              given to the forward function.\n",
      " |              Default: ``False``\n",
      " |\n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |\n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[tuple[torch.Tensor, ...], torch.Tensor], Union[tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |\n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |\n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |\n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |\n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |\n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |\n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward`` hooks on this\n",
      " |              :class:`torch.nn.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward`` hooks on\n",
      " |              this :class:`torch.nn.Module`. Note that global\n",
      " |              ``backward`` hooks registered with\n",
      " |              :func:`register_module_full_backward_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |\n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |\n",
      " |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward pre-hook on the module.\n",
      " |\n",
      " |      The hook will be called every time the gradients for the module are computed.\n",
      " |      The hook should have the following signature::\n",
      " |\n",
      " |          hook(module, grad_output) -> tuple[Tensor] or None\n",
      " |\n",
      " |      The :attr:`grad_output` is a tuple. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the output that will be used in place of :attr:`grad_output` in\n",
      " |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n",
      " |      all non-Tensor arguments.\n",
      " |\n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |\n",
      " |      .. warning ::\n",
      " |          Modifying inputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |\n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward_pre`` hooks on this\n",
      " |              :class:`torch.nn.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n",
      " |              on this :class:`torch.nn.Module`. Note that global\n",
      " |              ``backward_pre`` hooks registered with\n",
      " |              :func:`register_module_full_backward_pre_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |\n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |\n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Register a post-hook to be run after module's :meth:`~nn.Module.load_state_dict` is called.\n",
      " |\n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |\n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |\n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |\n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearing out both missing and unexpected keys will avoid an error.\n",
      " |\n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |\n",
      " |  register_load_state_dict_pre_hook(self, hook)\n",
      " |      Register a pre-hook to be run before module's :meth:`~nn.Module.load_state_dict` is called.\n",
      " |\n",
      " |      It should have the following signature::\n",
      " |          hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) -> None  # noqa: B950\n",
      " |\n",
      " |      Arguments:\n",
      " |          hook (Callable): Callable hook that will be invoked before\n",
      " |              loading the state dict.\n",
      " |\n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |\n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Add a parameter to the module.\n",
      " |\n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |\n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |\n",
      " |  register_state_dict_post_hook(self, hook)\n",
      " |      Register a post-hook for the :meth:`~torch.nn.Module.state_dict` method.\n",
      " |\n",
      " |      It should have the following signature::\n",
      " |          hook(module, state_dict, prefix, local_metadata) -> None\n",
      " |\n",
      " |      The registered hooks can modify the ``state_dict`` inplace.\n",
      " |\n",
      " |  register_state_dict_pre_hook(self, hook)\n",
      " |      Register a pre-hook for the :meth:`~torch.nn.Module.state_dict` method.\n",
      " |\n",
      " |      It should have the following signature::\n",
      " |          hook(module, prefix, keep_vars) -> None\n",
      " |\n",
      " |      The registered hooks can be used to perform pre-processing before the ``state_dict``\n",
      " |      call is made.\n",
      " |\n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this module.\n",
      " |\n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |\n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |\n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |\n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  set_extra_state(self, state: Any) -> None\n",
      " |      Set extra state contained in the loaded `state_dict`.\n",
      " |\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |\n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |\n",
      " |  set_submodule(self, target: str, module: 'Module', strict: bool = False) -> None\n",
      " |      Set the submodule given by ``target`` if it exists, otherwise throw an error.\n",
      " |\n",
      " |      .. note::\n",
      " |          If ``strict`` is set to ``False`` (default), the method will replace an existing submodule\n",
      " |          or create a new submodule if the parent module exists. If ``strict`` is set to ``True``,\n",
      " |          the method will only attempt to replace an existing submodule and throw an error if\n",
      " |          the submodule does not exist.\n",
      " |\n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |\n",
      " |      .. code-block:: text\n",
      " |\n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(3, 3, 3)\n",
      " |                  )\n",
      " |                  (linear): Linear(3, 3)\n",
      " |              )\n",
      " |          )\n",
      " |\n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |\n",
      " |      To override the ``Conv2d`` with a new submodule ``Linear``, you\n",
      " |      could call ``set_submodule(\"net_b.net_c.conv\", nn.Linear(1, 1))``\n",
      " |      where ``strict`` could be ``True`` or ``False``\n",
      " |\n",
      " |      To add a new submodule ``Conv2d`` to the existing ``net_b`` module,\n",
      " |      you would call ``set_submodule(\"net_b.conv\", nn.Conv2d(1, 1, 1))``.\n",
      " |\n",
      " |      In the above if you set ``strict=True`` and call\n",
      " |      ``set_submodule(\"net_b.conv\", nn.Conv2d(1, 1, 1), strict=True)``, an AttributeError\n",
      " |      will be raised because ``net_b`` does not have a submodule named ``conv``.\n",
      " |\n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |          module: The module to set the submodule to.\n",
      " |          strict: If ``False``, the method will replace an existing submodule\n",
      " |              or create a new submodule if the parent module exists. If ``True``,\n",
      " |              the method will only attempt to replace an existing submodule and throw an error\n",
      " |              if the submodule doesn't already exist.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If the ``target`` string is empty or if ``module`` is not an instance of ``nn.Module``.\n",
      " |          AttributeError: If at any point along the path resulting from\n",
      " |              the ``target`` string the (sub)path resolves to a non-existent\n",
      " |              attribute name or an object that is not an instance of ``nn.Module``.\n",
      " |\n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`.\n",
      " |\n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Return a dictionary containing references to the whole state of the module.\n",
      " |\n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |\n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |\n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |\n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |\n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |\n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |\n",
      " |      Example::\n",
      " |\n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |\n",
      " |  to(self, *args, **kwargs)\n",
      " |      Move and/or cast the parameters and buffers.\n",
      " |\n",
      " |      This can be called as\n",
      " |\n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |\n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |\n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |\n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |\n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |\n",
      " |      See below for examples.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |      Examples::\n",
      " |\n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |\n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |\n",
      " |  to_empty(self: ~T, *, device: Union[int, str, torch.device, NoneType], recurse: bool = True) -> ~T\n",
      " |      Move the parameters and buffers to the specified device without copying storage.\n",
      " |\n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |          recurse (bool): Whether parameters and buffers of submodules should\n",
      " |              be recursively moved to the specified device.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Set the module in training mode.\n",
      " |\n",
      " |      This has an effect only on certain modules. See the documentation of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, i.e., whether they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |\n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the XPU.\n",
      " |\n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |\n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |\n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |\n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |\n",
      " |  zero_grad(self, set_to_none: bool = True) -> None\n",
      " |      Reset gradients of all model parameters.\n",
      " |\n",
      " |      See similar function under :class:`torch.optim.Optimizer` for more context.\n",
      " |\n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |\n",
      " |  T_destination = ~T_destination\n",
      " |\n",
      " |  call_super_init = False\n",
      " |\n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c42163bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 29, 29]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1117037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba79ea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 29, 29])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5d34416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a2e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
