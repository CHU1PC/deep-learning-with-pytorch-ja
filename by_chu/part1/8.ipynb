{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099e7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "path = \"data\"\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83657b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af617d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5f8410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() \n",
    "                      else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031a3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.tanh3 = nn.Tanh()\n",
    "\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.tanh1(self.conv1(x)))\n",
    "        out = self.pool2(self.tanh2(self.conv2(out)))\n",
    "        out = out.view(-1, 8*8*8)\n",
    "        out = self.tanh3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca72194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70acbe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(F.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8*8*8)\n",
    "        out = F.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43736af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    cifar2, batch_size=64, shuffle=True,\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    cifar2_val, batch_size=64, shuffle=False,\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cc9d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1049, -0.0315]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(cifar2[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fd5bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 21:51:33.707841 Epoch 1, Train Loss 0.5703767980359922\n",
      "2025-08-11 21:51:37.456472 Epoch 10, Train Loss 0.34042285325800536\n",
      "2025-08-11 21:51:41.235358 Epoch 20, Train Loss 0.2998743922847092\n",
      "2025-08-11 21:51:45.366739 Epoch 30, Train Loss 0.276204632251126\n",
      "2025-08-11 21:51:49.581746 Epoch 40, Train Loss 0.253474707910969\n",
      "2025-08-11 21:51:53.803373 Epoch 50, Train Loss 0.23362333564811452\n",
      "2025-08-11 21:51:58.104837 Epoch 60, Train Loss 0.21777245549449495\n",
      "2025-08-11 21:52:02.358042 Epoch 70, Train Loss 0.20558011517593056\n",
      "2025-08-11 21:52:06.566790 Epoch 80, Train Loss 0.1929951187958763\n",
      "2025-08-11 21:52:10.959438 Epoch 90, Train Loss 0.18141046130828037\n",
      "2025-08-11 21:52:15.266507 Epoch 100, Train Loss 0.16724360046113373\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import torch.optim as optim\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"{datetime.datetime.now()} Epoch {epoch + 1}, Train Loss {train_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51310b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model: nn.Module, criterion, optimizer, data_loader: DataLoader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            total += labels.shape[0]\n",
    "            correct += (pred == labels).sum()\n",
    "        print(correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2541c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9355, device='mps:0')\n",
      "tensor(0.8895, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "accuracy(model, criterion, optimizer, train_loader)\n",
    "accuracy(model, criterion, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88efb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/birds_vs_airplanes.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "873f6513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"data/birds_vs_airplanes.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa67f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWidth(nn.Module):\n",
    "    def __init__(self, channel: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, channel, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channel, 16, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(16*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(F.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 16*8*8)\n",
    "        out = F.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14b61a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 21:54:00.303983 Epoch 1,  Train Loss 0.5841960660211599\n",
      "2025-08-11 21:54:06.021937 Epoch 10,  Train Loss 0.3507759719137933\n",
      "2025-08-11 21:54:12.304698 Epoch 20,  Train Loss 0.3119001829889929\n",
      "2025-08-11 21:54:18.666029 Epoch 30,  Train Loss 0.28346171481594157\n",
      "2025-08-11 21:54:25.084196 Epoch 40,  Train Loss 0.2611427181845258\n",
      "2025-08-11 21:54:31.294888 Epoch 50,  Train Loss 0.237025527485237\n",
      "2025-08-11 21:54:37.501029 Epoch 60,  Train Loss 0.22267879801950638\n",
      "2025-08-11 21:54:43.756725 Epoch 70,  Train Loss 0.20558584524188073\n",
      "2025-08-11 21:54:49.953732 Epoch 80,  Train Loss 0.18976376499909503\n",
      "2025-08-11 21:54:56.274946 Epoch 90,  Train Loss 0.17583720343317955\n",
      "2025-08-11 21:55:02.709130 Epoch 100,  Train Loss 0.1636143454415783\n"
     ]
    }
   ],
   "source": [
    "model = NetWidth(32).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        l2_norm = sum(p.pow(2.0).sum()\n",
    "                      for p in model.parameters())\n",
    "        loss = loss + 0.001*l2_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        print(f\"{datetime.datetime.now()} Epoch {epoch + 1}, \",\n",
    "                f\"Train Loss {train_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c5e06d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9565, device='mps:0')\n",
      "tensor(0.8965, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "accuracy(model, criterion, optimizer, train_loader)\n",
    "accuracy(model, criterion, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "367e5559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 21:56:12.564025 Epoch 1,  Train Loss 0.5729605356219468\n",
      "2025-08-11 21:56:18.802191 Epoch 10,  Train Loss 0.34454719456517774\n",
      "2025-08-11 21:56:25.843951 Epoch 20,  Train Loss 0.3066430930878706\n",
      "2025-08-11 21:56:32.771288 Epoch 30,  Train Loss 0.2768849319523307\n",
      "2025-08-11 21:56:39.772623 Epoch 40,  Train Loss 0.25399489710285406\n",
      "2025-08-11 21:56:46.714423 Epoch 50,  Train Loss 0.23087473118760785\n",
      "2025-08-11 21:56:53.765499 Epoch 60,  Train Loss 0.21044086370688336\n",
      "2025-08-11 21:57:00.791801 Epoch 70,  Train Loss 0.1935175801538358\n",
      "2025-08-11 21:57:07.686752 Epoch 80,  Train Loss 0.17906437249510151\n",
      "2025-08-11 21:57:14.778193 Epoch 90,  Train Loss 0.16627111357108804\n",
      "2025-08-11 21:57:21.588903 Epoch 100,  Train Loss 0.15376685184847777\n"
     ]
    }
   ],
   "source": [
    "model = NetWidth(64).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        l2_norm = sum((p ** 2).sum()\n",
    "                      for p in model.parameters())\n",
    "        loss = loss + 0.001*l2_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        print(f\"{datetime.datetime.now()} Epoch {epoch + 1}, \",\n",
    "                f\"Train Loss {train_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcc9d993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9644, device='mps:0')\n",
      "tensor(0.8925, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "accuracy(model, criterion, optimizer, train_loader)\n",
    "accuracy(model, criterion, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94a7624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, channel_size: int):\n",
    "        super().__init__()\n",
    "        self.channel_size = channel_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.channel_size, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.channel_size, self.channel_size // 2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.channel_size*8*8 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.conv1(x))\n",
    "        out = F.max_pool2d(self.dropout(out), kernel_size=2)\n",
    "        out = F.tanh(self.conv2(out))\n",
    "        out = F.max_pool2d(self.dropout(out), kernel_size=2)\n",
    "        out = out.view(-1, self.channel_size*8*8 // 2)\n",
    "        out = F.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4393067e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 22:33:34.617346 Epoch 1,  Train Loss 0.5741230517056337\n",
      "2025-08-11 22:33:40.711948 Epoch 10,  Train Loss 0.35681581895822173\n",
      "2025-08-11 22:33:47.319737 Epoch 20,  Train Loss 0.3113867296914386\n",
      "2025-08-11 22:33:54.002521 Epoch 30,  Train Loss 0.28294802234051336\n",
      "2025-08-11 22:34:00.713004 Epoch 40,  Train Loss 0.2621251658364466\n",
      "2025-08-11 22:34:07.335212 Epoch 50,  Train Loss 0.24592957878188723\n",
      "2025-08-11 22:34:14.004562 Epoch 60,  Train Loss 0.22858043105169468\n",
      "2025-08-11 22:34:20.535402 Epoch 70,  Train Loss 0.21547605097293854\n",
      "2025-08-11 22:34:27.172476 Epoch 80,  Train Loss 0.1968964502500121\n",
      "2025-08-11 22:34:33.959354 Epoch 90,  Train Loss 0.18962460694609173\n",
      "2025-08-11 22:34:40.603311 Epoch 100,  Train Loss 0.17678017254657807\n"
     ]
    }
   ],
   "source": [
    "model = NetDropout(64).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        l2_norm = sum((p ** 2).sum()\n",
    "                      for p in model.parameters())\n",
    "        loss = loss + 0.001*l2_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        print(f\"{datetime.datetime.now()} Epoch {epoch + 1}, \",\n",
    "                f\"Train Loss {train_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "724c3818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8803, device='mps:0')\n",
      "tensor(0.8520, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "accuracy(model, criterion, optimizer, train_loader)\n",
    "accuracy(model, criterion, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43c4d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, channel_size: int):\n",
    "        super().__init__()\n",
    "        self.channel_size = channel_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.channel_size, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.channel_size, self.channel_size // 2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.channel_size*8*8//2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(self.channel_size)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(self.channel_size // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.batch_norm1(self.conv1(x))\n",
    "        out = F.max_pool2d(F.tanh(out), 2)\n",
    "        out = self.batch_norm2(self.conv2(out))\n",
    "        out = F.max_pool2d(F.tanh(out), 2)\n",
    "        out = out.view(-1, self.channel_size*8*8//2)\n",
    "        out = F.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da7f3971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-11 22:51:13.083200 Epoch 1,  Train Loss 0.5621445676323714\n",
      "2025-08-11 22:51:21.040803 Epoch 10,  Train Loss 0.38095596916736313\n",
      "2025-08-11 22:51:29.713741 Epoch 20,  Train Loss 0.30905323746098073\n",
      "2025-08-11 22:51:38.223359 Epoch 30,  Train Loss 0.2510499076288977\n",
      "2025-08-11 22:51:46.658219 Epoch 40,  Train Loss 0.20655566150215782\n",
      "2025-08-11 22:51:56.081034 Epoch 50,  Train Loss 0.17033429206556575\n",
      "2025-08-11 22:52:05.339261 Epoch 60,  Train Loss 0.1514132310440586\n",
      "2025-08-11 22:52:13.846107 Epoch 70,  Train Loss 0.15066134236800444\n",
      "2025-08-11 22:52:22.374216 Epoch 80,  Train Loss 0.12592637790426328\n",
      "2025-08-11 22:52:30.960123 Epoch 90,  Train Loss 0.12960255843628743\n",
      "2025-08-11 22:52:39.659727 Epoch 100,  Train Loss 0.19561852434068727\n"
     ]
    }
   ],
   "source": [
    "model = NetBatchNorm(64).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        l2_norm = sum((p ** 2).sum()\n",
    "                      for p in model.parameters())\n",
    "        loss = loss + 0.001*l2_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "        print(f\"{datetime.datetime.now()} Epoch {epoch + 1}, \",\n",
    "                f\"Train Loss {train_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58bc5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9581, device='mps:0')\n",
      "tensor(0.8725, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "accuracy(model, criterion, optimizer, train_loader)\n",
    "accuracy(model, criterion, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2738b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
